{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25676,"status":"ok","timestamp":1766221574785,"user":{"displayName":"Nada Ammar","userId":"15542811381361415718"},"user_tz":-60},"id":"u2qaTl11jNpR","outputId":"86e9824d-1436-4161-a0fc-5277cc058eb8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n","\r0% [Waiting for headers] [Connected to cloud.r-project.org (108.157.173.54)] [C\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","\r                                                                               \rGet:4 https://cli.github.com/packages stable InRelease [3,917 B]\n","\r0% [2 InRelease 33.0 kB/128 kB 26%] [Waiting for headers] [Waiting for headers]\r                                                                               \rGet:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","\r0% [2 InRelease 64.9 kB/128 kB 51%] [5 InRelease 14.2 kB/129 kB 11%] [Waiting f\r0% [Waiting for headers] [5 InRelease 14.2 kB/129 kB 11%] [Waiting for headers]\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,966 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n","Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,858 kB]\n","Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,564 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [114 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [40.7 kB]\n","Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\n","Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n","Fetched 34.9 MB in 7s (4,777 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"]}],"source":["!apt-get update\n","!apt-get install openjdk-8-jdk-headless -qq \u003e /dev/null"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15031,"status":"ok","timestamp":1766221589807,"user":{"displayName":"Nada Ammar","userId":"15542811381361415718"},"user_tz":-60},"id":"UWhfxq-rjbj7","outputId":"4b3c8aac-2be5-4e16-f086-391872f7e28c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Spark initialized: 4.0.1\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder \\\n","    .appName(\"AirQualityPrediction \") \\\n","    .getOrCreate()\n","\n","\n","print(\"Spark initialized:\", spark.version)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10994,"status":"ok","timestamp":1766221600802,"user":{"displayName":"Nada Ammar","userId":"15542811381361415718"},"user_tz":-60},"id":"liRguV07kSAz","outputId":"69fdd6ff-bbed-402d-c977-44cbba11f15e"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+--------+------+-----------+--------+--------+-------------+-------+------------+-------+------------+-----------+----+----+------+----+----+\n","|      Date|    Time|CO(GT)|PT08.S1(CO)|NMHC(GT)|C6H6(GT)|PT08.S2(NMHC)|NOx(GT)|PT08.S3(NOx)|NO2(GT)|PT08.S4(NO2)|PT08.S5(O3)|   T|  RH|    AH|_c15|_c16|\n","+----------+--------+------+-----------+--------+--------+-------------+-------+------------+-------+------------+-----------+----+----+------+----+----+\n","|10/03/2004|18.00.00|   2,6|       1360|     150|    11,9|         1046|    166|        1056|    113|        1692|       1268|13,6|48,9|0,7578|NULL|NULL|\n","|10/03/2004|19.00.00|     2|       1292|     112|     9,4|          955|    103|        1174|     92|        1559|        972|13,3|47,7|0,7255|NULL|NULL|\n","|10/03/2004|20.00.00|   2,2|       1402|      88|     9,0|          939|    131|        1140|    114|        1555|       1074|11,9|54,0|0,7502|NULL|NULL|\n","|10/03/2004|21.00.00|   2,2|       1376|      80|     9,2|          948|    172|        1092|    122|        1584|       1203|11,0|60,0|0,7867|NULL|NULL|\n","|10/03/2004|22.00.00|   1,6|       1272|      51|     6,5|          836|    131|        1205|    116|        1490|       1110|11,2|59,6|0,7888|NULL|NULL|\n","+----------+--------+------+-----------+--------+--------+-------------+-------+------------+-------+------------+-----------+----+----+------+----+----+\n","only showing top 5 rows\n","Total rows: 9471\n"]}],"source":["file_path = \"/content/drive/MyDrive/finalyear_eng/spark/project/AirQualityUCI.csv\"\n","\n","data = spark.read.csv(file_path, header=True, inferSchema=True, sep=';')\n","data.show(5)\n","print(f\"Total rows: {data.count()}\")\n"]},{"cell_type":"markdown","metadata":{"id":"Wh_4VtMI2ElC"},"source":["# **Data Cleaning**"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5085,"status":"ok","timestamp":1766221605881,"user":{"displayName":"Nada Ammar","userId":"15542811381361415718"},"user_tz":-60},"id":"fP5vxmVAkR9P","outputId":"f59dc4ad-f839-49ac-f955-fe3c261ac22f"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Date: string (nullable = true)\n"," |-- Time: string (nullable = true)\n"," |-- COGT: double (nullable = true)\n"," |-- PT08_S1CO: double (nullable = true)\n"," |-- NMHCGT: double (nullable = true)\n"," |-- C6H6GT: double (nullable = true)\n"," |-- PT08_S2NMHC: double (nullable = true)\n"," |-- NOxGT: double (nullable = true)\n"," |-- PT08_S3NOx: double (nullable = true)\n"," |-- NO2GT: double (nullable = true)\n"," |-- PT08_S4NO2: double (nullable = true)\n"," |-- PT08_S5O3: double (nullable = true)\n"," |-- T: double (nullable = true)\n"," |-- RH: double (nullable = true)\n"," |-- AH: double (nullable = true)\n","\n","+----------+--------+----+---------+------+------+-----------+-----+----------+-----+----------+---------+----+----+------+\n","|      Date|    Time|COGT|PT08_S1CO|NMHCGT|C6H6GT|PT08_S2NMHC|NOxGT|PT08_S3NOx|NO2GT|PT08_S4NO2|PT08_S5O3|   T|  RH|    AH|\n","+----------+--------+----+---------+------+------+-----------+-----+----------+-----+----------+---------+----+----+------+\n","|10/03/2004|18.00.00| 2.6|   1360.0| 150.0|  11.9|     1046.0|166.0|    1056.0|113.0|    1692.0|   1268.0|13.6|48.9|0.7578|\n","|10/03/2004|19.00.00| 2.0|   1292.0| 112.0|   9.4|      955.0|103.0|    1174.0| 92.0|    1559.0|    972.0|13.3|47.7|0.7255|\n","|10/03/2004|20.00.00| 2.2|   1402.0|  88.0|   9.0|      939.0|131.0|    1140.0|114.0|    1555.0|   1074.0|11.9|54.0|0.7502|\n","|10/03/2004|21.00.00| 2.2|   1376.0|  80.0|   9.2|      948.0|172.0|    1092.0|122.0|    1584.0|   1203.0|11.0|60.0|0.7867|\n","|10/03/2004|22.00.00| 1.6|   1272.0|  51.0|   6.5|      836.0|131.0|    1205.0|116.0|    1490.0|   1110.0|11.2|59.6|0.7888|\n","+----------+--------+----+---------+------+------+-----------+-----+----------+-----+----------+---------+----+----+------+\n","only showing top 5 rows\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, when, regexp_replace\n","from pyspark.sql.types import DoubleType\n","\n","# Load data\n","data = spark.read.option(\"header\", True).option(\"sep\", \";\").csv(\"/content/drive/MyDrive/finalyear_eng/spark/project/AirQualityUCI.csv\")\n","\n","# Rename columns safely using toDF()\n","clean_cols = [c.replace('.', '_').replace('(', '').replace(')', '').replace(' ', '_') for c in data.columns]\n","data = data.toDF(*clean_cols)\n","\n","# Drop unnamed or extra columns\n","data = data.select([c for c in data.columns if not c.startswith(\"_c\")])\n","\n","# Replace commas with dots and cast to DoubleType\n","for c in data.columns:\n","    if c not in [\"Date\", \"Time\"]:\n","        data = data.withColumn(c, regexp_replace(col(c), \",\", \".\"))\n","        data = data.withColumn(c, col(c).cast(DoubleType()))\n","\n","# Replace -200 with null (missing sensor values)\n","for c in data.columns:\n","    if c not in [\"Date\", \"Time\"]:\n","        data = data.withColumn(c, when(col(c) == -200, None).otherwise(col(c)))\n","\n","# Drop rows with null target (CO_GT)\n","data = data.dropna(subset=[\"COGT\"])\n","\n","# Show schema and preview\n","data.printSchema()\n","data.show(5)\n"]},{"cell_type":"markdown","metadata":{"id":"RWlHrPyY1YJb"},"source":["# **Date/Time and Feature Engineering**"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1479,"status":"ok","timestamp":1766221607361,"user":{"displayName":"Nada Ammar","userId":"15542811381361415718"},"user_tz":-60},"id":"knA9xNRc1E3l","outputId":"18acf38a-faf8-493a-ce4a-f3edb50807c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----+---------+------+------+-----------+-----+----------+-----+----------+---------+----+----+------+-------------------+----+-----------+-----+\n","|COGT|PT08_S1CO|NMHCGT|C6H6GT|PT08_S2NMHC|NOxGT|PT08_S3NOx|NO2GT|PT08_S4NO2|PT08_S5O3|   T|  RH|    AH|           datetime|hour|day_of_week|month|\n","+----+---------+------+------+-----------+-----+----------+-----+----------+---------+----+----+------+-------------------+----+-----------+-----+\n","| 2.6|   1360.0| 150.0|  11.9|     1046.0|166.0|    1056.0|113.0|    1692.0|   1268.0|13.6|48.9|0.7578|2004-03-10 18:00:00|  18|          4|    3|\n","| 2.0|   1292.0| 112.0|   9.4|      955.0|103.0|    1174.0| 92.0|    1559.0|    972.0|13.3|47.7|0.7255|2004-03-10 19:00:00|  19|          4|    3|\n","| 2.2|   1402.0|  88.0|   9.0|      939.0|131.0|    1140.0|114.0|    1555.0|   1074.0|11.9|54.0|0.7502|2004-03-10 20:00:00|  20|          4|    3|\n","| 2.2|   1376.0|  80.0|   9.2|      948.0|172.0|    1092.0|122.0|    1584.0|   1203.0|11.0|60.0|0.7867|2004-03-10 21:00:00|  21|          4|    3|\n","| 1.6|   1272.0|  51.0|   6.5|      836.0|131.0|    1205.0|116.0|    1490.0|   1110.0|11.2|59.6|0.7888|2004-03-10 22:00:00|  22|          4|    3|\n","+----+---------+------+------+-----------+-----+----------+-----+----------+---------+----+----+------+-------------------+----+-----------+-----+\n","only showing top 5 rows\n"]}],"source":["from pyspark.sql.functions import concat_ws, to_timestamp, hour, dayofweek, month\n","\n","data = data.withColumn(\"datetime\", to_timestamp(concat_ws(' ', col(\"Date\"), col(\"Time\")), \"dd/MM/yyyy HH.mm.ss\"))\n","data = data.withColumn(\"hour\", hour(\"datetime\"))\n","data = data.withColumn(\"day_of_week\", dayofweek(\"datetime\"))\n","data = data.withColumn(\"month\", month(\"datetime\"))\n","\n","# Drop original Date and Time\n","df = data.drop(\"Date\", \"Time\")\n","df.show(5)\n"]},{"cell_type":"markdown","metadata":{"id":"IepC3VxV-LSH"},"source":["# **Feature Engineering**"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1766221607658,"user":{"displayName":"Nada Ammar","userId":"15542811381361415718"},"user_tz":-60},"id":"mRqAIaSaABy4","outputId":"832c12ab-1554-4b60-a4e8-ba5a7a4de506"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Date: string (nullable = true)\n"," |-- Time: string (nullable = true)\n"," |-- COGT: double (nullable = true)\n"," |-- PT08_S1CO: double (nullable = true)\n"," |-- NMHCGT: double (nullable = true)\n"," |-- C6H6GT: double (nullable = true)\n"," |-- PT08_S2NMHC: double (nullable = true)\n"," |-- NOxGT: double (nullable = true)\n"," |-- PT08_S3NOx: double (nullable = true)\n"," |-- NO2GT: double (nullable = true)\n"," |-- PT08_S4NO2: double (nullable = true)\n"," |-- PT08_S5O3: double (nullable = true)\n"," |-- T: double (nullable = true)\n"," |-- RH: double (nullable = true)\n"," |-- AH: double (nullable = true)\n"," |-- datetime: timestamp (nullable = false)\n"," |-- hour: integer (nullable = false)\n"," |-- day_of_week: integer (nullable = false)\n"," |-- month: integer (nullable = false)\n","\n"]}],"source":["from pyspark.sql.functions import col\n","\n","# Rename target column and clean column names (remove special chars)\n","for old_name in data.columns:\n","    new_name = old_name.replace(\"(\", \"\").replace(\")\", \"\").replace(\".\", \"\").replace(\" \", \"\")\n","    data = data.withColumnRenamed(old_name, new_name)\n","\n","data.printSchema()\n"]},{"cell_type":"markdown","metadata":{"id":"0Cb324pNBC_n"},"source":["Drop Nulls \u0026 Ensure Numeric Columns"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":474,"status":"ok","timestamp":1766221608137,"user":{"displayName":"Nada Ammar","userId":"15542811381361415718"},"user_tz":-60},"id":"rnv8CVa1-Ogy"},"outputs":[],"source":["from pyspark.sql.functions import col\n","\n","# Drop rows with nulls in important numeric columns\n","data = data.dropna(subset=[\"COGT\"])\n","\n","# Cast all numeric columns to DoubleType\n","from pyspark.sql.types import DoubleType\n","\n","for c in data.columns:\n","    if c not in [\"Date\", \"Time\", \"datetime\"]:\n","        data = data.withColumn(c, col(c).cast(DoubleType()))\n"]},{"cell_type":"markdown","metadata":{"id":"PX2U4Ou-BF18"},"source":["Filter Out Infinite or Corrupted Values"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":555,"status":"ok","timestamp":1766221608738,"user":{"displayName":"Nada Ammar","userId":"15542811381361415718"},"user_tz":-60},"id":"dKYVsBFkA5HR"},"outputs":[],"source":["from pyspark.sql.functions import when\n","\n","for c in data.columns:\n","    if c not in [\"Date\", \"Time\", \"datetime\"]:\n","        data = data.withColumn(c, when(col(c) \u003c -100, None).otherwise(col(c)))\n","\n","data = data.na.drop()\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8491,"status":"ok","timestamp":1766221617231,"user":{"displayName":"Nada Ammar","userId":"15542811381361415718"},"user_tz":-60},"id":"fHw9y6gFA7dM","outputId":"e169472f-ba3f-4ba4-b0e6-d9039ff2f33d"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+----+\n","|     scaled_features|COGT|\n","+--------------------+----+\n","|[5.62408771114498...| 2.6|\n","|[5.34288332558773...| 2.0|\n","|[5.79777277281269...| 2.2|\n","|[5.69025344892316...| 2.2|\n","|[5.26017615336501...| 1.6|\n","+--------------------+----+\n","only showing top 5 rows\n"]}],"source":["from pyspark.ml.feature import VectorAssembler, StandardScaler\n","from pyspark.ml import Pipeline\n","\n","feature_cols = [c for c in data.columns if c not in [\"Date\", \"Time\", \"datetime\", \"COGT\"]]\n","\n","assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n","scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n","\n","pipeline = Pipeline(stages=[assembler, scaler])\n","data_prep = pipeline.fit(data).transform(data).select(\"scaled_features\", \"COGT\")\n","data_prep.show(5)\n"]},{"cell_type":"markdown","metadata":{"id":"LXxdLSgeBRi2"},"source":["# **Train/Test Split**"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":156,"status":"ok","timestamp":1766221617394,"user":{"displayName":"Nada Ammar","userId":"15542811381361415718"},"user_tz":-60},"id":"aaXy5DR5BTcu"},"outputs":[],"source":["from pyspark.ml.regression import LinearRegression\n","\n","# Split data into training and test sets\n","train_data, test_data = data_prep.randomSplit([0.8, 0.2], seed=42)\n"]},{"cell_type":"markdown","metadata":{"id":"U3Hc44MF889x"},"source":["# **Linear Regression Model**"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10216,"status":"ok","timestamp":1766221627617,"user":{"displayName":"Nada Ammar","userId":"15542811381361415718"},"user_tz":-60},"id":"tO_aiaeQ8-1d","outputId":"481f7f51-81a8-4597-9dd9-fdbc4fe8a70f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Coefficients: [0.3141766434969541,0.1681623429882212,1.034449126692926,-0.26555581935532585,0.41296035684808674,-0.017915457026001745,0.08745745414749614,-0.15703339454239415,-0.1824425378949758,-0.19599804124110645,-0.12682432204628835,0.12255673991564155,0.05802935178219222,-0.00821473401169162,0.004770619315899792]\n","Intercept: 0.7849807058583937\n"]}],"source":["# Initialize Linear Regression\n","lr = LinearRegression(featuresCol=\"scaled_features\", labelCol=\"COGT\")\n","\n","# Fit the model\n","lr_model = lr.fit(train_data)\n","\n","# Print coefficients and intercept\n","print(\"Coefficients:\", lr_model.coefficients)\n","print(\"Intercept:\", lr_model.intercept)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9168,"status":"ok","timestamp":1766221636790,"user":{"displayName":"Nada Ammar","userId":"15542811381361415718"},"user_tz":-60},"id":"IvUX6cRCMPO4","outputId":"d143d564-2dff-4996-e32b-a6ff04bf31a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+----+-------------------+\n","|     scaled_features|COGT|         prediction|\n","+--------------------+----+-------------------+\n","|[3.24625650974177...| 0.3| 0.4321488986077659|\n","|[3.32482832335335...| 0.3| 0.3169125748816603|\n","|[3.33723439918676...| 0.7| 0.6404230389216417|\n","|[3.41580621279835...| 0.7|0.46390637636746657|\n","|[3.45302444029857...| 0.4| 0.6016112815132286|\n","+--------------------+----+-------------------+\n","only showing top 5 rows\n","RMSE: 0.2148549682626931\n","R2: 0.9754801569611979\n"]}],"source":["# Make predictions\n","predictions = lr_model.transform(test_data)\n","predictions.select(\"scaled_features\", \"COGT\", \"prediction\").show(5)\n","\n","# Evaluate using RMSE and R2\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","evaluator_rmse = RegressionEvaluator(labelCol=\"COGT\", predictionCol=\"prediction\", metricName=\"rmse\")\n","evaluator_r2 = RegressionEvaluator(labelCol=\"COGT\", predictionCol=\"prediction\", metricName=\"r2\")\n","\n","rmse = evaluator_rmse.evaluate(predictions)\n","r2 = evaluator_r2.evaluate(predictions)\n","\n","print(f\"RMSE: {rmse}\")\n","print(f\"R2: {r2}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":591},"id":"6h9cesVyGe3C"},"outputs":[{"name":"stdout","output_type":"stream","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://81db127c2ee155f0eb.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\u003cdiv\u003e\u003ciframe src=\"https://81db127c2ee155f0eb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["import gradio as gr\n","import pandas as pd\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import VectorAssembler, StandardScaler\n","from pyspark.ml.regression import LinearRegressionModel\n","\n","unfitted_pipeline = Pipeline(stages=[assembler, scaler])\n","fitted_pipeline_model = unfitted_pipeline.fit(data)\n","\n","# Extract assembler and scaler models (now fitted transformers) from the fitted pipeline model\n","assembler_model = fitted_pipeline_model.stages[0]\n","scaler_model = fitted_pipeline_model.stages[1]\n","\n","# --- Features used in training ---\n","MODEL_FEATURES = [\n","    \"PT08_S1CO\", \"NMHCGT\", \"C6H6GT\", \"PT08_S2NMHC\", \"NOxGT\",\n","    \"PT08_S3NOx\", \"NO2GT\", \"PT08_S4NO2\", \"PT08_S5O3\",\n","    \"T\", \"RH\", \"AH\", \"hour\", \"day_of_week\", \"month\"\n","]\n","\n","# --- Explanations for dropdowns ---\n","EXPLAIN = {\n","    \"PT08_S1CO\": \"CO-sensitive sensor response (related to CO concentration).\",\n","    \"NMHCGT\": \"Total non-methane hydrocarbons (NMHC).\",\n","    \"C6H6GT\": \"Benzene (C6H6) concentration in ¬µg/m¬≥.\",\n","    \"PT08_S2NMHC\": \"Sensor tuned to NMHC gases.\",\n","    \"NOxGT\": \"Nitrogen oxides concentration in ppb.\",\n","    \"PT08_S3NOx\": \"Sensor tuned to NOx gases.\",\n","    \"NO2GT\": \"Nitrogen dioxide concentration in ¬µg/m¬≥.\",\n","    \"PT08_S4NO2\": \"Sensor tuned to NO‚ÇÇ gases.\",\n","    \"PT08_S5O3\": \"Sensor tuned to ozone (O‚ÇÉ).\",\n","    \"T\": \"Temperature in ¬∞C.\",\n","    \"RH\": \"Relative humidity (%).\",\n","    \"AH\": \"Absolute humidity.\",\n","    \"hour\": \"Hour of day (0‚Äì23).\",\n","    \"day_of_week\": \"Day of week (1=Sunday ... 7=Saturday).\",\n","    \"month\": \"Month of the year (1‚Äì12).\"\n","}\n","\n","# --- Example dropdown values --- (from previous definitions)\n","CHOICES = {\n","    \"PT08_S1CO\": [500, 1000, 1500, 2000],\n","    \"NMHCGT\": [50, 100, 150, 200],\n","    \"C6H6GT\": [5, 10, 15, 20],\n","    \"PT08_S2NMHC\": [600, 800, 1000, 1200],\n","    \"NOxGT\": [80, 120, 160, 200],\n","    \"PT08_S3NOx\": [800, 1000, 1200, 1400],\n","    \"NO2GT\": [90, 110, 130, 150],\n","    \"PT08_S4NO2\": [1000, 1300, 1500, 1700],\n","    \"PT08_S5O3\": [800, 1000, 1200, 1400],\n","    \"T\": [5, 15, 25, 35],\n","    \"RH\": [30, 50, 70, 90],\n","    \"AH\": [0.5, 0.8, 1.0, 1.2],\n","    \"hour\": [6, 12, 18, 23],\n","    \"day_of_week\": [1, 3, 5, 7],\n","    \"month\": [1, 4, 7, 10]\n","}\n","\n","ui_inputs = []\n","for feat in MODEL_FEATURES:\n","    label = f\"{feat} ‚Äî {EXPLAIN.get(feat, '')}\"\n","    choices = CHOICES.get(feat)\n","    default = choices[1] if choices else None\n","    ui_inputs.append(gr.Dropdown(choices, label=label, value=default))\n","\n","def predict_with_conclusion(*vals):\n","    # Convert input to float (Dropdown values are strings by default)\n","    numeric_vals = [float(v) for v in vals]\n","\n","    # Create Spark DataFrame\n","    input_data = pd.DataFrame([numeric_vals], columns=MODEL_FEATURES)\n","    input_df = spark.createDataFrame(input_data)\n","\n","    # Assemble features\n","    vector_df = assembler_model.transform(input_df)\n","\n","    # Scale features\n","    scaled_df = scaler_model.transform(vector_df)\n","\n","    # Predict using trained Linear Regression (lr_model is globally available)\n","    prediction = lr_model.transform(scaled_df).collect()[0][\"prediction\"]\n","\n","    # --- Interpretation --- (from previous definitions)\n","    if prediction \u003c 1.0:\n","        condition = \"Excellent\"\n","        conclusion = (\n","            \"Air condition: Excellent ‚Äî CO levels are very low.\\n\"\n","            \"Health impact: Safe for all outdoor activities.\\n\"\n","            \"Recommendation: No precautions needed.\"\n","        )\n","    elif prediction \u003c 2.0:\n","        condition = \"Moderate\"\n","        conclusion = (\n","            \"Air condition: Moderate ‚Äî acceptable CO concentration.\\n\"\n","            \"Health impact: Sensitive people should stay cautious.\\n\"\n","            \"Recommendation: Avoid heavy outdoor exercise if sensitive.\"\n","        )\n","    elif prediction \u003c 4.0:\n","        condition = \"Unhealthy for Sensitive Groups\"\n","        conclusion = (\n","            \"Air condition: Unhealthy for sensitive groups ‚Äî elevated CO.\\n\"\n","            \"Health impact: Risk for those with heart/lung issues.\\n\"\n","            \"Recommendation: Limit outdoor activities.\"\n","        )\n","    else:\n","        condition = \"Poor\"\n","        conclusion = (\n","            \"Air condition: Poor ‚Äî high CO concentration.\\n\"\n","            \"Health impact: Risky for all population.\\n\"\n","            \"Recommendation: Stay indoors if possible.\"\n","        )\n","\n","    # Final formatted text\n","    result_text = (\n","        f\"Predicted CO(GT): {prediction:.2f} mg/m¬≥\\n\"\n","        f\"Air Quality Category: {condition}\\n\\n\"\n","        f\"{conclusion}\"\n","    )\n","\n","    return result_text\n","\n","# --- Launch Gradio --- (with a more specific title and description)\n","gr.Interface(\n","    fn=predict_with_conclusion,\n","    inputs=ui_inputs,\n","    outputs=gr.Textbox(label=\"Prediction and Air Quality Analysis\", lines=10),\n","    title=\"üå´Ô∏è Air Quality Prediction (PySpark)\",\n","    description=\"Predict CO(GT) concentration based on air sensor readings using a trained Linear Regression model. Choose from example values below.\"\n",").launch(share=True , debug=True)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM828VgNFwg6nWSzmyC+mTH","mount_file_id":"1VaBpzSQVzQk70ch9h4YiGWKGm8LqPW-q","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}